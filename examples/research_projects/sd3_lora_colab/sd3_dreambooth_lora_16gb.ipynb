{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6xLZDgOajbd"
      },
      "source": [
        "# Running Stable Diffusion 3 (SD3) DreamBooth LoRA training under 16GB GPU VRAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jPZpMTwafua"
      },
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIYdn1woOS1n"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U git+https://github.com/huggingface/diffusers\n",
        "!pip install -q -U \\\n",
        "    transformers \\\n",
        "    accelerate \\\n",
        "    wandb \\\n",
        "    bitsandbytes \\\n",
        "    peft"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qUNciw6aov2"
      },
      "source": [
        "As SD3 is gated, before using it with diffusers you first need to go to the [Stable Diffusion 3 Medium Hugging Face page](https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers), fill in the form and accept the gate. Once you are in, you need to log in so that your system knows you’ve accepted the gate. Use the command below to log in:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bpk5FleeK1NR"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcF7gl4FasJV"
      },
      "source": [
        "## Clone `diffusers`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgSOJYglJKiM"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/huggingface/diffusers\n",
        "%cd diffusers/examples/research_projects/sd3_lora_colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9dBawr6ayRY"
      },
      "source": [
        "## Download instance data images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68,
          "referenced_widgets": [
            "42710a51145f456c98b0015ea41a9b87",
            "eab2b11433c2408aa1d5d642b698a421",
            "7ec0a58d8f0f41f5b9ec4b9cf3639bbd",
            "f3b69f19bd39491a9a86b58919febe6e",
            "42f980844a1f4d498a7ce699e4078b33",
            "f5ea5d03d89844569ef91be3204da8bd",
            "5dbfbbb885634a13b52c6b1623704773",
            "023257c3fd8a4cbbb267ca42e1893e5b",
            "79d7d1f95398486998007102d8a9729b",
            "eb8b569d6ffc4ab29d7f279751dbb1bb",
            "d272e7c5edf940e8bfbb770a4afafb34"
          ]
        },
        "id": "La1rBYWFNjEP",
        "outputId": "20911af6-16ed-43ca-983d-515abb8e9f02"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42710a51145f456c98b0015ea41a9b87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/faith_knox/stable'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "local_dir = \"./faith_knox/stable\"\n",
        "snapshot_download(\n",
        "    \"diffusers/dog-example\",\n",
        "    local_dir=local_dir, repo_type=\"dataset\",\n",
        "    ignore_patterns=\".gitattributes\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbsIzdjbOzgi"
      },
      "outputs": [],
      "source": [
        "!rm -rf dog/.cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88sOTn2ga07q"
      },
      "source": [
        "## Compute embeddings\n",
        "\n",
        "Here we are using the default instance prompt \"a photo of sks dog\". But you can configure this. Refer to the `compute_embeddings.py` script for details on other supported arguments."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/compute_embeddings.py\n",
        "# Paste your script contents here\n",
        "import os\n",
        "\n",
        "def main():\n",
        "    print(\"Running embedding computation...\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "QNQ93_kD7jcA",
        "outputId": "ce7d87c4-b527-4893-d157-38e13355be43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/compute_embeddings.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/compute_embeddings.py\n"
      ],
      "metadata": {
        "id": "Y-2Fjkyh7nkn",
        "outputId": "06951433-36d6-4e50-a23a-cea6c4826aea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running embedding computation...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ha6hPLpHLM8c",
        "outputId": "7ff7d391-750f-4102-b6d1-351eead30dc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running embedding computation...\n"
          ]
        }
      ],
      "source": [
        "!python compute_embeddings.py --instance_data_dir=\"./faith_knox/stable\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10iMo-RUa_yv"
      },
      "source": [
        "## Clear memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YltRmPgMuNa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "\n",
        "def flush():\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO5oEtOJbBS9"
      },
      "source": [
        "## Train!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuJ6hdm2M4Aw"
      },
      "outputs": [],
      "source": [
        "!accelerate launch train_dreambooth_lora_sd3_miniature.py \\\n",
        "  --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-3-medium-diffusers\"  \\\n",
        "  --instance_data_dir=\"dog\" \\\n",
        "  --data_df_path=\"sample_embeddings.parquet\" \\\n",
        "  --output_dir=\"trained-sd3-lora-miniature\" \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --instance_prompt=\"a photo of sks dog\" \\\n",
        "  --resolution=1024 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=4 --gradient_checkpointing \\\n",
        "  --use_8bit_adam \\\n",
        "  --learning_rate=1e-4 \\\n",
        "  --report_to=\"wandb\" \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --max_train_steps=500 \\\n",
        "  --seed=\"0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itS-dsJ0gjy3"
      },
      "source": [
        "Training will take about an hour to complete depending on the length of your dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpOuL7S1bI6j"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clfMv4jKfQzb"
      },
      "outputs": [],
      "source": [
        "flush()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "np03SXHkbKpG"
      },
      "outputs": [],
      "source": [
        "from diffusers import DiffusionPipeline\n",
        "import torch\n",
        "\n",
        "pipeline = DiffusionPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-3-medium-diffusers\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "lora_output_path = \"trained-sd3-lora-miniature\"\n",
        "pipeline.load_lora_weights(\"trained-sd3-lora-miniature\")\n",
        "\n",
        "pipeline.enable_sequential_cpu_offload()\n",
        "\n",
        "image = pipeline(\"a photo of sks dog in a bucket\").images[0]\n",
        "image.save(\"bucket_dog.png\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "1dDVoV5_31Kw",
        "outputId": "d161ce70-e0e7-439f-87da-9a33f3dbffc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/faithknoxtraining/stable.zip\" -d /content/faith_knox\n"
      ],
      "metadata": {
        "id": "flApi7Mt4D9p",
        "outputId": "5c100168-dc08-4049-8145-f973210ebb80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/faithknoxtraining/stable.zip\n",
            "   creating: /content/faith_knox/stable/\n",
            "   creating: /content/faith_knox/stable/compressed/\n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._compressed  \n",
            "  inflating: /content/faith_knox/stable/._compressed  \n",
            "  inflating: /content/faith_knox/stable/th-2645293770.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-2645293770.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-2645293770.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-3916788417.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-3916788417.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-3916788417.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-4019533498.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-4019533498.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-4019533498.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-4048935629.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-4048935629.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-4048935629.jpg  \n",
            "  inflating: /content/faith_knox/stable/OIP-3706928389.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._OIP-3706928389.jpg  \n",
            "  inflating: /content/faith_knox/stable/._OIP-3706928389.jpg  \n",
            "  inflating: /content/faith_knox/stable/OIP-3790432823.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._OIP-3790432823.jpg  \n",
            "  inflating: /content/faith_knox/stable/._OIP-3790432823.jpg  \n",
            "  inflating: /content/faith_knox/stable/OIP-3737482923.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._OIP-3737482923.jpg  \n",
            "  inflating: /content/faith_knox/stable/._OIP-3737482923.jpg  \n",
            "  inflating: /content/faith_knox/stable/OIP-2315505557.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._OIP-2315505557.jpg  \n",
            "  inflating: /content/faith_knox/stable/._OIP-2315505557.jpg  \n",
            "  inflating: /content/faith_knox/stable/OIP-1781213911.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._OIP-1781213911.jpg  \n",
            "  inflating: /content/faith_knox/stable/._OIP-1781213911.jpg  \n",
            "  inflating: /content/faith_knox/stable/OIP-2145099125.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._OIP-2145099125.jpg  \n",
            "  inflating: /content/faith_knox/stable/._OIP-2145099125.jpg  \n",
            "  inflating: /content/faith_knox/stable/OIP-3738375961.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._OIP-3738375961.jpg  \n",
            "  inflating: /content/faith_knox/stable/._OIP-3738375961.jpg  \n",
            "  inflating: /content/faith_knox/stable/OIP-2139407485.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._OIP-2139407485.jpg  \n",
            "  inflating: /content/faith_knox/stable/._OIP-2139407485.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-3438605434.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-3438605434.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-3438605434.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-830327802.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-830327802.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-830327802.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-1860959800.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-1860959800.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-1860959800.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-2980995508.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-2980995508.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-2980995508.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-2786453902.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-2786453902.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-2786453902.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-383856024.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-383856024.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-383856024.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-760087416.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-760087416.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-760087416.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-1619497890.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-1619497890.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-1619497890.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-3976900785.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-3976900785.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-3976900785.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-3943514982.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-3943514982.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-3943514982.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-3746840891.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-3746840891.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-3746840891.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-946163439.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-946163439.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-946163439.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-2770876431.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-2770876431.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-2770876431.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-2573974975.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-2573974975.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-2573974975.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-1818333187.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-1818333187.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-1818333187.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-1382427480.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-1382427480.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-1382427480.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-3672781522.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-3672781522.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-3672781522.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-1688958291.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-1688958291.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-1688958291.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-2274424925.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-2274424925.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-2274424925.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-3309930439.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-3309930439.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-3309930439.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-901598435.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-901598435.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-901598435.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-2833377823.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-2833377823.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-2833377823.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-1331271725.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-1331271725.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-1331271725.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-1203102743.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-1203102743.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-1203102743.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-3787817975.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-3787817975.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-3787817975.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-76273784.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-76273784.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-76273784.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-236477962.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-236477962.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-236477962.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-4007410672.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-4007410672.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-4007410672.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-3908183134.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-3908183134.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-3908183134.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-3993801170.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-3993801170.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-3993801170.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-2824528528.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-2824528528.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-2824528528.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-2155859488.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-2155859488.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-2155859488.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-1152950192.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-1152950192.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-1152950192.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-1161398286.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-1161398286.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-1161398286.jpg  \n",
            "  inflating: /content/faith_knox/stable/Brandy--2178052077.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._Brandy--2178052077.jpg  \n",
            "  inflating: /content/faith_knox/stable/._Brandy--2178052077.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-3402639818.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-3402639818.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-3402639818.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-593939314.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-593939314.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-593939314.jpg  \n",
            "  inflating: /content/faith_knox/stable/th-315854340.jpg  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/._th-315854340.jpg  \n",
            "  inflating: /content/faith_knox/stable/._th-315854340.jpg  \n",
            "   creating: /content/faith_knox/stable/jpgs/\n",
            "  inflating: /content/faith_knox/stable/compressed/IMG_7530.png  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/compressed/._IMG_7530.png  \n",
            "  inflating: /content/faith_knox/stable/compressed/._IMG_7530.png  \n",
            "  inflating: /content/faith_knox/stable/compressed/IMG_7529.png  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/compressed/._IMG_7529.png  \n",
            "  inflating: /content/faith_knox/stable/compressed/._IMG_7529.png  \n",
            "  inflating: /content/faith_knox/stable/compressed/IMG_7528.png  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/compressed/._IMG_7528.png  \n",
            "  inflating: /content/faith_knox/stable/compressed/._IMG_7528.png  \n",
            "  inflating: /content/faith_knox/stable/compressed/IMG_7527.png  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/compressed/._IMG_7527.png  \n",
            "  inflating: /content/faith_knox/stable/compressed/._IMG_7527.png  \n",
            "  inflating: /content/faith_knox/stable/compressed/IMG_6819.png  \n",
            "  inflating: /content/faith_knox/__MACOSX/stable/compressed/._IMG_6819.png  \n",
            "  inflating: /content/faith_knox/stable/compressed/._IMG_6819.png  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_2603.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_6317.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_1875.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4919.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4886.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_0148.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_5030.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_6262.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_5019.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4887.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4071.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_1874.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_3246.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_6316.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_2602.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_6314.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_2614.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4265.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_2600.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_1876.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_5032.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_5542.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_3133.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_2601.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_6315.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_1867.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_1873.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_3137.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_6259.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_6265.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_0601.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_6258.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_3136.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4895.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_1872.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_1866.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_9792.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_2612.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4263.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_3097.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_1870.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_9394.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_3134.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_5021.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_5034.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_9197.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4896.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_3914.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_1871.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_2613.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_1143.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4985.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4370.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_9697.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_3147.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4776.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4986.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_3151.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_5520.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4367.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_5521.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_3150.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4987.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_9737.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_2662.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_9086.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4983.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4439.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_0677.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4438.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_3155.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4982.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_3235.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_2665.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4348.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_0660.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_6576.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4349.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_9692.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4981.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_2664.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_3546.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_2245.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_2084.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_0678.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_0679.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_0651.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_9311.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_2244.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4741.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4557.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_9930.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_9313.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_8025.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_0690.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_0135.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_2496.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4232.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_9935.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_1762.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_2243.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4140.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_0131.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_9698.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_3148.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4141.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_2242.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_9934.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_1761.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_0133.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_1760.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4988.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_2490.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4977.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_3925.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_1868.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_1920.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_3138.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_6257.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_1706.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_1921.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_1869.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_3924.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_2621.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_3265.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_2740.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_9198.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4866.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_2620.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_5836.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_2618.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_2624.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_3076.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_9413.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_0146.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4452.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_9412.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_1714.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_9214.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_2625.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_6319.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_2619.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_2627.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4915.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_3908.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_3075.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_9362.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_0150.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_9149.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_3074.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_1677.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_4914.jpg  \n",
            "  inflating: /content/faith_knox/stable/jpgs/IMG_2626.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!--instance_data_dir=\"/content/faith_knox\"\n"
      ],
      "metadata": {
        "id": "7uPmDFgW4QwU",
        "outputId": "f65e84e1-de3f-4346-f09f-28e4b26b3786",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: --: invalid option\n",
            "Usage:\t/bin/bash [GNU long option] [option] ...\n",
            "\t/bin/bash [GNU long option] [option] script-file ...\n",
            "GNU long options:\n",
            "\t--debug\n",
            "\t--debugger\n",
            "\t--dump-po-strings\n",
            "\t--dump-strings\n",
            "\t--help\n",
            "\t--init-file\n",
            "\t--login\n",
            "\t--noediting\n",
            "\t--noprofile\n",
            "\t--norc\n",
            "\t--posix\n",
            "\t--pretty-print\n",
            "\t--rcfile\n",
            "\t--restricted\n",
            "\t--verbose\n",
            "\t--version\n",
            "Shell options:\n",
            "\t-ilrsD or -c command or -O shopt_option\t\t(invocation only)\n",
            "\t-abefhkmnptuvxBCHP or -o option\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDfrY2opjGjD"
      },
      "source": [
        "Note that inference will be very slow in this case because we're loading and unloading individual components of the models and that introduces significant data movement overhead. Refer to [this resource](https://huggingface.co/blog/sd3#memory-optimizations-for-sd3) for more memory optimization related techniques."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/huggingface/diffusers/main/examples/dreambooth/train_dreambooth_lora_sd3.py\n"
      ],
      "metadata": {
        "id": "D5OyLUHr5qX5",
        "outputId": "652fab42-e34a-443a-9c36-7f8eedf630df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-10 20:33:07--  https://raw.githubusercontent.com/huggingface/diffusers/main/examples/dreambooth/train_dreambooth_lora_sd3.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 82055 (80K) [text/plain]\n",
            "Saving to: ‘train_dreambooth_lora_sd3.py’\n",
            "\n",
            "\r          train_dre   0%[                    ]       0  --.-KB/s               \rtrain_dreambooth_lo 100%[===================>]  80.13K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-05-10 20:33:07 (5.37 MB/s) - ‘train_dreambooth_lora_sd3.py’ saved [82055/82055]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch train_dreambooth_lora_sd3.py \\\n",
        "  --pretrained_model_name_or_path=stabilityai/stable-diffusion-3-medium-diffusers \\\n",
        "  --instance_data_dir=/content/faith_knox \\\n",
        "  --data_df_path=sample_embeddings.parquet \\\n",
        "  --output_dir=/content/trained-faithknox-lora \\\n",
        "  --mixed_precision=fp16 \\\n",
        "  --instance_prompt=\"a photo of sks faithknox woman\" \\\n",
        "  --resolution=1024 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=4 \\\n",
        "  --gradient_checkpointing \\\n",
        "  --use_8bit_adam \\\n",
        "  --learning_rate=1e-4 \\\n",
        "  --report_to=wandb \\\n",
        "  --lr_scheduler=constant \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --max_train_steps=500 \\\n",
        "  --seed=0\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "X0Uh-XbG58Wt",
        "outputId": "732683d7-14cc-4845-96d4-2d41eeadbacc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-05-10 20:34:25.970548: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746909265.989943    3097 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746909265.995933    3097 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-10 20:34:26.015297: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/train_dreambooth_lora_sd3.py\", line 75, in <module>\n",
            "    check_min_version(\"0.34.0.dev0\")\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/diffusers/utils/__init__.py\", line 148, in check_min_version\n",
            "    raise ImportError(error_message)\n",
            "ImportError: This example requires a source install from HuggingFace diffusers (see `https://huggingface.co/docs/diffusers/installation#install-from-source`), but the version found is 0.33.1.\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 50, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 1213, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 795, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'train_dreambooth_lora_sd3.py', '--pretrained_model_name_or_path=stabilityai/stable-diffusion-3-medium-diffusers', '--instance_data_dir=/content/faith_knox', '--data_df_path=sample_embeddings.parquet', '--output_dir=/content/trained-faithknox-lora', '--mixed_precision=fp16', '--instance_prompt=a photo of sks faithknox woman', '--resolution=1024', '--train_batch_size=1', '--gradient_accumulation_steps=4', '--gradient_checkpointing', '--use_8bit_adam', '--learning_rate=1e-4', '--report_to=wandb', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--max_train_steps=500', '--seed=0']' returned non-zero exit status 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "MNsARDw68JSd",
        "outputId": "3224a99f-da0f-48cc-a685-fcc4a968afc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ftfy regex tqdm\n",
        "!pip install git+https://github.com/openai/CLIP.git\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9up5xIAU_oG9",
        "outputId": "764103ee-b698-41e8-d4ec-9617335845d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ftfy\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy) (0.2.13)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ftfy\n",
            "Successfully installed ftfy-6.3.1\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-i31lt1vw\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-i31lt1vw\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (6.3.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (0.21.0+cu124)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->clip==1.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->clip==1.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->clip==1.0) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m117.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369490 sha256=c095507008cb293035cec2bfa6fcc1089edd0660034a0462f498499b744837c7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sm8ry5ru/wheels/3f/7c/a4/9b490845988bf7a4db33674d52f709f088f64392063872eb9a\n",
            "Successfully built clip\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, clip\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed clip-1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import clip\n",
        "import torch\n",
        "from PIL import Image\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "ruia7V52AM32"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load the pre-trained CLIP model\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device)\n"
      ],
      "metadata": {
        "id": "t7u36iqeAa26",
        "outputId": "88456f32-c45e-4c71-811a-1e14ae5beaee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 338M/338M [00:04<00:00, 83.6MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the images\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Once uploaded, they will be available in the current working directory\n",
        "# Example: Display the names of uploaded files\n",
        "print(uploaded.keys())\n"
      ],
      "metadata": {
        "id": "fNV4gySYCfS1",
        "outputId": "9b410764-a48c-4e86-abe3-2d59f4a7d274",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c6edcefe-13e5-4af1-a72b-5b8c16b7b21c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c6edcefe-13e5-4af1-a72b-5b8c16b7b21c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving stable.zip to stable.zip\n",
            "dict_keys(['stable.zip'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# List everything in the root directory\n",
        "for f in os.listdir('/content'):\n",
        "    print(f)\n"
      ],
      "metadata": {
        "id": "HvtvVuhbKI4k",
        "outputId": "fab3f0de-4fed-42b1-d9ae-a31810dd2f2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".config\n",
            "stable.zip\n",
            "faith_knox\n",
            "compute_embeddings.py\n",
            "drive\n",
            "train_dreambooth_lora_sd3.py\n",
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q stable.zip -d /content/stable_unzipped\n"
      ],
      "metadata": {
        "id": "rTrXQWXjK3Rp"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "unzipped_path = '/content/stable_unzipped'\n",
        "for fname in os.listdir(unzipped_path):\n",
        "    print(fname)\n"
      ],
      "metadata": {
        "id": "ylFN--cxK8IU",
        "outputId": "92c83af4-cc5e-44af-eb98-d383083fd004",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__MACOSX\n",
            "stable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import glob module to search for image files\n",
        "import glob\n",
        "\n",
        "# Adjust for the actual path inside 'stable' folder\n",
        "image_dir = '/content/stable_unzipped/stable'\n",
        "\n",
        "image_paths = glob.glob(f\"{image_dir}/**/*.jpg\", recursive=True) + \\\n",
        "              glob.glob(f\"{image_dir}/**/*.png\", recursive=True) + \\\n",
        "              glob.glob(f\"{image_dir}/**/*.jpeg\", recursive=True)\n",
        "\n",
        "print(f\"Found {len(image_paths)} images.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "h8oo6vKeLEqb",
        "outputId": "7c1c19de-2ba1-4917-f1f0-d3a2ef419cba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 208 images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "hwyIS-vfLXiT"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the CLIP model and processor\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n"
      ],
      "metadata": {
        "id": "Lc-1x_TCLvFJ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Function to compute embeddings for images\n",
        "def compute_image_embeddings(image_paths):\n",
        "    embeddings = []\n",
        "\n",
        "    # Loop through all the image paths and compute embeddings\n",
        "    for image_path in tqdm(image_paths, desc=\"Processing images\"):\n",
        "        image = Image.open(image_path)  # Open the image\n",
        "\n",
        "        # Process the image using the CLIP processor\n",
        "        inputs = processor(images=image, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "        # Generate the image embeddings from the model\n",
        "        with torch.no_grad():\n",
        "            image_features = model.get_image_features(**inputs)\n",
        "\n",
        "        embeddings.append(image_features.cpu().numpy())  # Store the embeddings\n",
        "\n",
        "    return np.array(embeddings)  # Convert list to numpy array for easier handling\n"
      ],
      "metadata": {
        "id": "LPfiLUZrMDiS"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute embeddings for all images\n",
        "embeddings = compute_image_embeddings(image_paths)\n",
        "\n",
        "# Save the embeddings to a .npy file (you can use this later for training or other purposes)\n",
        "np.save('/content/faith_knox_embeddings.npy', embeddings)\n"
      ],
      "metadata": {
        "id": "vnF1tnOSMGAD",
        "outputId": "dec35528-fb89-4be1-9bab-7c329c672246",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing images: 100%|██████████| 208/208 [01:09<00:00,  2.99it/s]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "42710a51145f456c98b0015ea41a9b87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eab2b11433c2408aa1d5d642b698a421",
              "IPY_MODEL_7ec0a58d8f0f41f5b9ec4b9cf3639bbd",
              "IPY_MODEL_f3b69f19bd39491a9a86b58919febe6e"
            ],
            "layout": "IPY_MODEL_42f980844a1f4d498a7ce699e4078b33"
          }
        },
        "eab2b11433c2408aa1d5d642b698a421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5ea5d03d89844569ef91be3204da8bd",
            "placeholder": "​",
            "style": "IPY_MODEL_5dbfbbb885634a13b52c6b1623704773",
            "value": "Fetching 5 files: 100%"
          }
        },
        "7ec0a58d8f0f41f5b9ec4b9cf3639bbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_023257c3fd8a4cbbb267ca42e1893e5b",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79d7d1f95398486998007102d8a9729b",
            "value": 5
          }
        },
        "f3b69f19bd39491a9a86b58919febe6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb8b569d6ffc4ab29d7f279751dbb1bb",
            "placeholder": "​",
            "style": "IPY_MODEL_d272e7c5edf940e8bfbb770a4afafb34",
            "value": " 5/5 [00:00&lt;00:00, 336.14it/s]"
          }
        },
        "42f980844a1f4d498a7ce699e4078b33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5ea5d03d89844569ef91be3204da8bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dbfbbb885634a13b52c6b1623704773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "023257c3fd8a4cbbb267ca42e1893e5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79d7d1f95398486998007102d8a9729b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb8b569d6ffc4ab29d7f279751dbb1bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d272e7c5edf940e8bfbb770a4afafb34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}